# Copyright (c) 2024, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[project]
name = "nemo_curator"
description = "Scalable Data Preprocessing Tool for Training Large Language Models"
readme = { file = "README.md", content-type = "text/markdown" }
authors = [
    { name = "Ryan Wolf", email = "rywolf@nvidia.com" },
    { name = "Joseph Jennings", email = "jjennings@nvidia.com" },
    { name = "Mostofa Patwary", email = "mpatwary@nvidia.com" },
    { name = "Sandeep Subramanian", email = "sasubramania@nvidia.com" },
    { name = "Shrimai Prabhumoye", email = "sprabhumoye@nvidia.com" },
    { name = "Ayush Dattagupta", email = "adattagupta@nvidia.com" },
    { name = "Vibhu Jawa", email = "vjawa@nvidia.com" },
    { name = "Jiwei Liu", email = "jiweil@nvidia.com" },
    { name = "Sarah Yurick", email = "syurick@nvidia.com" },
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.12",
]
requires-python = ">=3.10"
dependencies = [
    "awscli>=1.22.55",
    "beautifulsoup4",
    "charset_normalizer>=3.1.0",
    "comment_parser",
    "crossfit>=0.0.8",
    "dask-mpi>=2021.11.0",
    "dask[complete]>=2021.7.1",
    "datasets",
    "distributed>=2021.7.1",
    "fasttext==0.9.3",
    "ftfy==6.1.1",
    "in-place==0.5.0",
    "jieba==0.42.1",
    "justext==3.0.1",
    "lxml_html_clean",
    "mecab-python3",
    "mwparserfromhell==0.6.5",
    "numpy<2",
    "openai",
    "peft",
    "platformdirs",
    "presidio-analyzer==2.2.351",
    "presidio-anonymizer==2.2.351",
    "pycld2",
    "resiliparse",
    "sentencepiece",
    "spacy>=3.6.0, <3.8.0",
    # TODO: Remove this pin once newer version is released
    "transformers==4.46.3",
    "unidic-lite==1.0.8",
    "usaddress==0.5.10",
    "warcio==1.7.4",
    "zstandard==0.18.0",
]
dynamic = ["version"]

[project.optional-dependencies]
# Installs CPU + GPU text curation modules
cuda12x = [
    "cudf-cu12>=24.12",
    "cugraph-cu12>=24.12",
    "cuml-cu12>=24.12",
    "dask-cuda>=24.12",
    "dask-cudf-cu12>=24.12",
    "spacy[cuda12x]>=3.6.0, <3.8.0",
]
# Installs CPU + GPU text curation modules with RAPIDS Nightlies
cuda12x_nightly = [
    "cudf-cu12>=25.02.0a0,<=25.02",
    "cugraph-cu12>=25.02.0a0,<=25.02",
    "cuml-cu12>=25.02.0a0,<=25.02",
    "dask-cuda>=25.02.0a0,<=25.02",
    "dask-cudf-cu12>=25.02.0a0,<=25.02",
    "spacy[cuda12x]>=3.6.0, <3.8.0",
]
# Installs CPU + GPU text and image curation modules
image = [
    "nvidia-dali-cuda120",
    "nvidia-nvjpeg2k-cu12",
    "timm>=1.0.8",
    "nemo_curator[cuda12x]",
]
# Installs CPU + GPU text and image curation modules with RAPIDS Nightlies
image_nightly = [
    "nvidia-dali-cuda120",
    "nvidia-nvjpeg2k-cu12",
    "timm>=1.0.8",
    "nemo_curator[cuda12x_nightly]",
]
# Installs bitext curation modules
bitext = [
    "huggingface-hub",
    "tqdm",
    "transformers",
    "nemo_curator[cuda12x]",
]
# Installs all of the above with Stable RAPIDS
all = [
    "nemo_curator[image]",
    "nemo_curator[bitext]",
]
# Installs all of the above with RAPIDS Nightlies
all_nightly = [
    "nemo_curator[image_nightly]",
]

[project.scripts]
get_common_crawl_urls = "nemo_curator.scripts.get_common_crawl_urls:console_script"
get_wikipedia_urls = "nemo_curator.scripts.get_wikipedia_urls:console_script"
download_and_extract = "nemo_curator.scripts.download_and_extract:console_script"
text_cleaning = "nemo_curator.scripts.text_cleaning:console_script"
add_id = "nemo_curator.scripts.add_id:console_script"
make_data_shards = "nemo_curator.scripts.make_data_shards:console_script"
prepare_fasttext_training_data = "nemo_curator.scripts.prepare_fasttext_training_data:console_script"
train_fasttext = "nemo_curator.scripts.train_fasttext:console_script"
filter_documents = "nemo_curator.scripts.filter_documents:console_script"
separate_by_metadata = "nemo_curator.scripts.separate_by_metadata:console_script"
prepare_task_data = "nemo_curator.scripts.prepare_task_data:console_script"
find_matching_ngrams = "nemo_curator.scripts.find_matching_ngrams:console_script"
remove_matching_ngrams = "nemo_curator.scripts.remove_matching_ngrams:console_script"
gpu_compute_minhashes = "nemo_curator.scripts.fuzzy_deduplication.compute_minhashes:console_script"
minhash_buckets = "nemo_curator.scripts.fuzzy_deduplication.minhash_lsh:console_script"
jaccard_map_buckets = "nemo_curator.scripts.fuzzy_deduplication.map_buckets:console_script"
jaccard_shuffle = "nemo_curator.scripts.fuzzy_deduplication.jaccard_shuffle:console_script"
jaccard_compute = "nemo_curator.scripts.fuzzy_deduplication.jaccard_compute:console_script"
gpu_connected_component = "nemo_curator.scripts.fuzzy_deduplication.connected_components:console_script"
buckets_to_edges = "nemo_curator.scripts.fuzzy_deduplication.buckets_to_edges:console_script"
gpu_exact_dups = "nemo_curator.scripts.find_exact_duplicates:console_script"
deidentify = "nemo_curator.scripts.find_pii_and_deidentify:console_script"
domain_classifier_inference = "nemo_curator.scripts.classifiers.domain_classifier_inference:console_script"
quality_classifier_inference = "nemo_curator.scripts.classifiers.quality_classifier_inference:console_script"
aegis_classifier_inference = "nemo_curator.scripts.classifiers.aegis_classifier_inference:console_script"
fineweb_edu_classifier_inference = "nemo_curator.scripts.classifiers.fineweb_edu_classifier_inference:console_script"
instruction_data_guard_classifier_inference = "nemo_curator.scripts.classifiers.instruction_data_guard_classifier_inference:console_script"
multilingual_domain_classifier_inference = "nemo_curator.scripts.classifiers.multilingual_domain_classifier_inference:console_script"
content_type_classifier_inference = "nemo_curator.scripts.classifiers.content_type_classifier_inference:console_script"
prompt_task_complexity_classifier_inference = "nemo_curator.scripts.classifiers.prompt_task_complexity_classifier_inference:console_script"
verify_classification_results = "nemo_curator.scripts.verify_classification_results:console_script"
blend_datasets = "nemo_curator.scripts.blend_datasets:console_script"
semdedup_extract_embeddings = "nemo_curator.scripts.semdedup.compute_embeddings:console_script"
semdedup_clustering = "nemo_curator.scripts.semdedup.clustering:console_script"
semdedup_extract_unique_ids = "nemo_curator.scripts.semdedup.extract_dedup_data:console_script"

[project.urls]
Homepage = "https://github.com/NVIDIA/NeMo-Curator"

[tool.black]
line-length = 88

[tool.isort]
profile = "black"  # black-compatible
line_length = 88  # should match black parameters
py_version = 310

[tool.pytest.ini_options]
markers = [
    "gpu: marks tests as GPU tests (deselect with '-m \"not gpu\"')"
]

[tool.setuptools.dynamic]
version = { attr = "nemo_curator.package_info.__version__" }

[tool.setuptools.packages.find]
include = ["*"]
exclude = ["tests", "tests.*"]
