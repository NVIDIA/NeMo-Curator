{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Preference Data Generation Using Meta's Llama 3.1 405B Instruct\n",
    "\n",
    "The following notebook will demonstrate how to leverage [Meta's Llama 3.1 405B Instruct](https://build.nvidia.com/meta/llama3.1-405b-instruct), and [Nemotron-4 340B Reward](https://build.nvidia.com/nvidia/nemotron-4-340b-reward) through [build.nvidia.com](https://build.nvidia.com/explore/discover).\n",
    "\n",
    "The build will be a demonstration of the following pipeline.\n",
    "\n",
    "![image](./SDG%20Pipeline.png)\n",
    "\n",
    "The flow will be split into 2 general parts: \n",
    "\n",
    "1. **Synthetic Response Generation**: A domain specific input query will be provided by the developer - at which point Llama 3.1 405B Instruct will be leveraged to generate ~150 questions. Then, Llama 3.1 405B Instruct will be used to generated 2 responses for each question. \n",
    "2. **Reward Model as a Judge**: Nemotron-4 340B Reward will be used to score the 2 responses per question to be used for further alignment training via [NeMo Aligner](https://github.com/NVIDIA/NeMo-Aligner)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build.nvidia.com API Key Set-up!\n",
    "\n",
    "In order to access the endpoints through [build.nvidia.com](https://build.nvidia.com/explore/discover), an API key is required. \n",
    "\n",
    "A trial API key is made available with 1,000 tokens (or 5,000 tokens for corporate emails) - the example below will leverage ~4,500 tokens of data, but can be extended beyond that limit using local instances of the models.\n",
    "\n",
    "There are two steps to get a trial API key:\n",
    "\n",
    "1. Login (or sign up) through [build.nvidia.com](https://build.nvidia.com/)\n",
    "2. Click the `Get API Key` button available on the the `meta/llama3.1-405b-instruct` page, found [here](https://build.nvidia.com/meta/llama3.1-405b-instruct).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Subtopics, questions, and responses with Meta's Llama 3.1 405B Instruct\n",
    "\n",
    "The first part of the notebook will cover the creation of raw synthetic data from Meta's Llama 3.1 405B Instruct model.\n",
    "\n",
    "The data generated with this model can be used in accordance with [Meta's Llama 3.1 License]()\n",
    "\n",
    "### NEED LICENSE LINK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates for Synthetic Data Generation\n",
    "\n",
    "To generate questions and responses, there are a few prompt templates required:\n",
    "\n",
    "1. A prompt template to generate subtopics from a user provided topic\n",
    "2. A prompt template to generate questions for a given subtopic\n",
    "2. A prompt template to generate responses for a given question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_GENERATION_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Given a topic, generate a list of {n_subtopics} subtopics that are related to the topic.\n",
    "\n",
    "The topic is: {topic}\n",
    "\n",
    "The list must be without numbers, and without any description of the subtopics. The subtopics should be separated by a comma. There must be no other text than the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Given a topic, generate {n_questions} questions that could be asked about that topic. Your response should be in a list format.\n",
    "\n",
    "The topic is: {sub_topic}\n",
    "\n",
    "The list must be without numbers. The questions should be separated by a newline character. There must be no other text than the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Given a question, generate 2 responses that could be given to that question. Your response should be in a list format.\n",
    "\n",
    "The question is: {question}\n",
    "\n",
    "The list must be in the format:\n",
    "\n",
    "RESPONSE A: Response A text here\n",
    "RESPONSE B: Response B text here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined below are the parameters that will be used throughout the notebook to generate numbers of datapoints. \n",
    "\n",
    "1. `n_subtopics`, for the given topic `10` sub-topics will be generated by Meta's Llama 3.1 405B Instruct\n",
    "2. `n_questions`, for the given sub-topic, `10` questions will be generated by Llama 3.1 405B Instruct\n",
    "\n",
    "> NOTE: Using the default parameters above - there will be 10 sub-topics, each with 10 questions, each with 2 (hardcoded) responses. That is a total of an estimated ~200 rows of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subtopics = 10\n",
    "n_questions = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting OpenAI Client for Synthetic Data Generation\n",
    "\n",
    "Due to [build.nvidia.com](https://build.nvidia.com/)'s integration with the OpenAI API template - the OpenAI Python library can be used to interact with Meta's Llama 3.1 405B Instruct and Nemotron-4 340B Reward.\n",
    "\n",
    "To begin, install the [OpenAI Python library](https://github.com/openai/openai-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the NVIDIA API key obtained above in order to ensure access to both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Please enter your NVIDIA API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the OpenAI Async client will enable quick and efficient data generation.\n",
    "\n",
    "It's as easy as pointing the `base_url` parameter to `https://integrate.api.nvidia.com/v1` - and providing the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = os.environ[\"NVIDIA_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Subtopics\n",
    "\n",
    "To start things off, subtopics will be generated for the provided topic. \n",
    "\n",
    "> NOTE: The parameters of `temperature`, `top_p`, and `max_tokens` can be customized to individual preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_subtopics(client, topic, n_subtopics):\n",
    "    prompt = TOPIC_GENERATION_PROMPT_TEMPLATE.format(topic=topic, n_subtopics=n_subtopics)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"meta/llama-3.1-405b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main topic can be defined below - for the example in the notebook, \"Machine Learning\" will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Machine Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will call the Meta's Llama 3.1 405B Instruct endpoint - and return a list of subtopics separated by commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = await generate_subtopics(client, topic=topic, n_subtopics=n_subtopics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output conforms to the expected format below.\n",
    "\n",
    "> NOTE: It is possible that additional data cleaning, or formatting may be necessary depending on the prompt templates used. Be sure to confirm the format of the generated data at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Natural Language Processing, Computer Vision, Predictive Modeling, Clustering, Dimensionality Reduction, Neural Networks\n"
     ]
    }
   ],
   "source": [
    "print(responses.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the data being generated in a comma separated list, Python's `.split(\",\")` will convert the string into a usable list for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtopic_list = responses.choices[0].message.content.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Questions from Subtopic List\n",
    "\n",
    "With a list of subtopics, the next step will be to generate `n_questions`, for each subtopic.\n",
    "\n",
    "First, there needs to be a function to generate \"batches\" of questions.\n",
    "\n",
    "> NOTE: It would suitable to generate a single question per topic at a time, but more care would be needed to confirm there were no duplicate questions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_questions(client, sub_topic, n_questions):\n",
    "    prompt = QUESTION_PROMPT_TEMPLATE.format(sub_topic=sub_topic, n_questions=n_questions)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"meta/llama-3.1-405b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step leverages [`asyncio`](https://docs.python.org/3/library/asyncio.html) from Python's standard library for efficient API calls to [build.nvidia.com](https://build.nvidia.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def question_generator(client, subtopic_list, n_question):\n",
    "    tasks = [generate_questions(client, subtopic, n_question) for subtopic in subtopic_list]\n",
    "    question_list = await asyncio.gather(*tasks)\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to running in a notebook environment - it is necessary to use `nest_asyncio` to run an event loop during the current Jupyter event loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "question_list = asyncio.run(question_generator(client, subtopic_list, n_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to examine the output of the above process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is supervised learning and how does it differ from unsupervised learning?\\n\\nHow does supervised learning work in machine learning algorithms?\\n\\nWhat are the advantages and disadvantages of using supervised learning in real-world applications?\\n\\nCan supervised learning be used for regression tasks, or is it limited to classification tasks?\\n\\nWhat is the role of labeled data in supervised learning, and how is it used to train models?\\n\\nHow do supervised learning algorithms handle missing or noisy data in the training set?\\n\\nWhat are some common supervised learning algorithms, and how do they differ from one another?\\n\\nHow can supervised learning be used for image classification tasks, such as object detection and facial recognition?\\n\\nWhat are some techniques for evaluating the performance of supervised learning models, and what metrics are commonly used?\\n\\nCan supervised learning be used in conjunction with other machine learning techniques, such as reinforcement learning or deep learning?',\n",
       " 'What are the main differences between supervised and unsupervised learning in machine learning?\\n\\nHow does unsupervised learning identify patterns in data without prior knowledge of the expected output?\\n\\nWhat are some common applications of unsupervised learning in real-world industries?\\n\\nCan unsupervised learning be used for anomaly detection, and if so, how?\\n\\nWhat is the role of clustering algorithms in unsupervised learning, and how do they work?\\n\\nHow does dimensionality reduction contribute to the unsupervised learning process?\\n\\nWhat are the advantages and disadvantages of using k-means clustering in unsupervised learning?\\n\\nHow does unsupervised learning handle high-dimensional data, and what techniques are used to reduce dimensionality?\\n\\nWhat is the relationship between unsupervised learning and generative models, such as Generative Adversarial Networks (GANs)?\\n\\nWhat are some common evaluation metrics used to assess the performance of unsupervised learning models?',\n",
       " 'What is the main goal of reinforcement learning in artificial intelligence?\\n\\nHow does reinforcement learning differ from supervised and unsupervised learning?\\n\\nWhat is the role of an agent in a reinforcement learning system?\\n\\nCan you explain the concept of a reward function in reinforcement learning?\\n\\nHow does the Q-learning algorithm work in reinforcement learning?\\n\\nWhat is the difference between on-policy and off-policy reinforcement learning?\\n\\nHow does reinforcement learning handle the exploration-exploitation trade-off?\\n\\nWhat is the role of deep learning in reinforcement learning?\\n\\nCan you explain the concept of policy gradients in reinforcement learning?\\n\\nHow is reinforcement learning applied in real-world applications such as robotics and game playing?',\n",
       " 'What is the fundamental difference between deep learning and traditional machine learning approaches?\\n\\nHow do deep neural networks handle complex data such as images, speech, and text?\\n\\nWhat is the role of activation functions in deep learning models?\\n\\nCan deep learning models be used for both supervised and unsupervised learning tasks?\\n\\nHow do convolutional neural networks (CNNs) and recurrent neural networks (RNNs) differ in their applications?\\n\\nWhat is the concept of overfitting in deep learning, and how can it be addressed?\\n\\nHow does batch normalization improve the training process of deep neural networks?\\n\\nWhat is the significance of transfer learning in deep learning, and how is it applied?\\n\\nCan deep learning models be interpreted and explained, or are they black boxes?\\n\\nHow do deep learning models handle adversarial attacks and data poisoning?',\n",
       " 'What are the primary applications of Natural Language Processing in everyday life?\\n\\nHow does Natural Language Processing differ from traditional computer programming languages?\\n\\nCan Natural Language Processing be used to improve human-computer interaction, and if so, how?\\n\\nWhat role does machine learning play in Natural Language Processing?\\n\\nWhat are some common challenges faced by developers when implementing Natural Language Processing systems?\\n\\nHow does Natural Language Processing handle nuances of human language, such as idioms and sarcasm?\\n\\nWhat are some potential uses of Natural Language Processing in data analysis and science?\\n\\nCan Natural Language Processing systems be used to generate human-like text, and if so, what are the implications?\\n\\nHow does Natural Language Processing impact the field of customer service and support?\\n\\nWhat are some current limitations of Natural Language Processing, and how are researchers working to address them?',\n",
       " 'What are the primary applications of computer vision in the field of robotics?\\n\\nHow does computer vision differ from image processing, and what are the key challenges in integrating these two fields?\\n\\nWhat role does machine learning play in the development of computer vision systems, and what are some common algorithms used?\\n\\nCan computer vision systems be used to recognize and classify objects in real-time, and if so, how?\\n\\nWhat are some of the key challenges in developing computer vision systems that can operate effectively in low-light environments?\\n\\nHow does computer vision contribute to the development of autonomous vehicles, and what are some of the key applications in this area?\\n\\nWhat are some of the most common computer vision techniques used in medical imaging and diagnostics?\\n\\nCan computer vision systems be used to recognize and analyze human emotions and behavior, and if so, how?\\n\\nWhat are some of the key considerations when designing computer vision systems for use in surveillance and security applications?\\n\\nHow does computer vision intersect with other fields, such as natural language processing and human-computer interaction?',\n",
       " 'What is predictive modeling and how is it used in real-world applications?\\n\\nHow does predictive modeling differ from descriptive and prescriptive analytics?\\n\\nWhat are some common techniques used in predictive modeling, such as regression and decision trees?\\n\\nWhat role does data quality play in the accuracy of predictive models?\\n\\nCan predictive models be used to identify causal relationships between variables?\\n\\nHow do you evaluate the performance of a predictive model, and what metrics are commonly used?\\n\\nWhat are some common challenges and limitations of predictive modeling, such as overfitting and underfitting?\\n\\nHow can predictive models be used to inform business decisions and drive strategic outcomes?\\n\\nWhat is the relationship between predictive modeling and machine learning, and how do they overlap?\\n\\nWhat are some emerging trends and advancements in predictive modeling, such as the use of deep learning and ensemble methods?',\n",
       " 'What is clustering and how is it used in data analysis?\\n\\nHow does clustering differ from classification in machine learning?\\n\\nWhat are the different types of clustering algorithms, and when are they used?\\n\\nCan clustering be used for both structured and unstructured data?\\n\\nHow do you determine the optimal number of clusters for a given dataset?\\n\\nWhat is the role of distance measures in clustering, and how do different measures affect results?\\n\\nHow does clustering handle outliers and noisy data?\\n\\nCan clustering be used for real-time data, or is it limited to batch processing?\\n\\nHow do you evaluate the quality of clusters generated by a clustering algorithm?\\n\\nWhat are some common applications of clustering in business, healthcare, and social sciences?',\n",
       " 'What is dimensionality reduction and why is it necessary in data analysis?\\n\\nHow does dimensionality reduction affect the quality and accuracy of data?\\n\\nWhat are the differences between linear and non-linear dimensionality reduction techniques?\\n\\nCan you explain the concept of curse of dimensionality and how dimensionality reduction helps to address it?\\n\\nWhat are the most commonly used dimensionality reduction techniques and their applications?\\n\\nHow does Principal Component Analysis (PCA) work and what are its limitations?\\n\\nWhat is the difference between feature selection and feature extraction in dimensionality reduction?\\n\\nHow does t-Distributed Stochastic Neighbor Embedding (t-SNE) work and what are its advantages?\\n\\nCan you explain the concept of manifold learning and its relationship to dimensionality reduction?\\n\\nWhat are the challenges and limitations of dimensionality reduction in high-dimensional data?',\n",
       " 'What is the basic structure of a neural network and how do its components interact?\\n\\nHow do neural networks learn and improve their performance over time?\\n\\nWhat is the difference between supervised, unsupervised, and reinforcement learning in neural networks?\\n\\nCan neural networks be used for tasks other than classification and regression?\\n\\nHow do convolutional neural networks (CNNs) and recurrent neural networks (RNNs) differ from traditional neural networks?\\n\\nWhat is the role of activation functions in neural networks and how do different functions affect the output?\\n\\nHow do neural networks handle missing or noisy data in the training set?\\n\\nWhat is overfitting in neural networks and how can it be prevented?\\n\\nCan neural networks be used for real-time processing and decision-making?\\n\\nHow do neural networks compare to other machine learning models in terms of performance and interpretability?']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list for each question is now collected into a single long list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list_formatted = []\n",
    "\n",
    "for question_set in question_list:\n",
    "    question_list_formatted += question_set.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_list_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Responses from Question List\n",
    "\n",
    "Using the question list, Meta's Llama 3.1 405B Instruct can be used to generate responses to the questions. \n",
    "\n",
    "The first things needed is a function that will be used to generate the response from [build.nvidia.com](https://build.nvidia.com/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_responses(client, question):\n",
    "    prompt = RESPONSE_PROMPT_TEMPLATE.format(question=question)\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"meta/llama-3.1-405b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `asycio` library allows efficient use of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def response_generator(client, question_list):\n",
    "    tasks = [generate_responses(client, question) for question in question_list]\n",
    "    response_list = await asyncio.gather(*tasks)\n",
    "    return response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_list = asyncio.run(response_generator(client, question_list_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning is a type of machine learning where the algorithm is trained on labeled data, meaning the data is already tagged with the correct output. The goal of supervised learning is to learn a mapping between input data and the corresponding output labels, so the algorithm can make predictions on new, unseen data. In contrast, unsupervised learning involves training an algorithm on unlabeled data, and the goal is to identify patterns or structure in the data without any prior knowledge of the expected output.\\n\\nRESPONSE B: Supervised learning is a machine learning approach where the model is trained on a dataset that includes both input data and corresponding target outputs. The model learns to map inputs to outputs based on the labeled examples, and its performance is evaluated on a separate test dataset. Unsupervised learning, on the other hand, involves training a model on a dataset without any labeled outputs. The model must find ways to identify relationships, patterns, or groupings within the data on its own, without any explicit guidance or feedback. This approach is often used for tasks like clustering, dimensionality reduction, or anomaly detection.',\n",
       " 'Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning in machine learning algorithms works by training a model on labeled data, where the correct output is already known. The algorithm learns to map inputs to outputs based on the labeled data, and its performance is evaluated on a separate test dataset. The goal is to make predictions on new, unseen data by generalizing the patterns learned from the training data. For example, in image classification, a supervised learning algorithm would be trained on a dataset of images labeled as \"cats\" or \"dogs\", and then it would be able to classify new images as either \"cats\" or \"dogs\" based on the features it learned from the training data.\\n\\nRESPONSE B: Supervised learning is a type of machine learning where an algorithm is trained on a dataset that includes both input data and corresponding output labels. The algorithm learns to identify patterns and relationships between the input data and output labels, and uses this information to make predictions on new data. The process involves three main steps: data preparation, model training, and model evaluation. During training, the algorithm is presented with the labeled data and adjusts its parameters to minimize the difference between its predictions and the actual output labels. Once trained, the model can be used to make predictions on new data, and its performance can be evaluated using metrics such as accuracy, precision, and recall.',\n",
       " 'Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning has several advantages, including high accuracy and efficiency in solving well-defined problems, as well as the ability to learn from large datasets. However, it also has some disadvantages, such as requiring a large amount of labeled training data, being sensitive to noise and outliers, and being limited in its ability to handle complex, real-world problems that involve multiple variables and uncertainties. Additionally, supervised learning models can be prone to overfitting, especially when the training data is limited or biased.\\n\\nRESPONSE B: The main advantages of supervised learning are its ability to learn from examples and improve over time, as well as its ability to handle high-dimensional data and make accurate predictions. However, supervised learning also has some significant disadvantages, including the need for large amounts of labeled training data, which can be time-consuming and expensive to obtain, and the risk of model bias and overfitting. Furthermore, supervised learning models can be limited in their ability to generalize to new, unseen data, and may not perform well in situations where the underlying relationships between variables are complex or non-linear.',\n",
       " 'Here are two possible responses to the question:\\n\\nRESPONSE A: Supervised learning can be used for both classification and regression tasks. In fact, regression is a type of supervised learning where the target variable is continuous, and the goal is to predict a numerical value. Many supervised learning algorithms, such as linear regression, decision trees, and neural networks, can be used for regression tasks.\\n\\nRESPONSE B: Supervised learning is not limited to classification tasks, and it can be used for regression tasks as well. Regression is a type of supervised learning where the goal is to establish a relationship between the input features and a continuous target variable. Supervised learning algorithms can learn this relationship from labeled data and make predictions on new, unseen data, making it a suitable approach for regression tasks.',\n",
       " \"Here are two possible responses to the question:\\n\\nRESPONSE A: Labeled data plays a crucial role in supervised learning as it provides the model with a clear understanding of the relationship between input data and the corresponding output. The labeled data is used to train the model, where the model learns to map inputs to outputs based on the labeled examples. The model is trained to minimize the error between its predictions and the actual labels, allowing it to learn from the data and make accurate predictions on new, unseen data.\\n\\nRESPONSE B: In supervised learning, labeled data serves as a guide for the model to learn from, allowing it to develop a mapping between input data and the corresponding labels. The model is trained on the labeled data, using the labels as a reference point to adjust its parameters and make predictions. As the model is trained, it becomes increasingly accurate in its predictions, and the labeled data provides a benchmark for evaluating the model's performance. By using labeled data to train the model, supervised learning enables the development of highly accurate models that can be applied to a wide range of applications.\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_response_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to move to the next stage, a dataset will be created in `.jsonl` format and will store questions with the responses generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_pair_list = []\n",
    "for question, response_set in zip(question_list_formatted, question_response_list):\n",
    "    question_response_pair_list.append(\n",
    "        {\n",
    "            \"question\" : question, \n",
    "            \"responses\" : {\n",
    "                \"response_a\" : {\"response\" : response_set.split(\"RESPONSE B:\")[0].replace(\"RESPONSE A:\", \"\").strip().split(\"\\n\\n\")[-1].strip()},\n",
    "                \"response_b\" : {\"response\" : response_set.split(\"RESPONSE B:\")[-1].split(\"\\n\\n\")[0].strip()}\n",
    "            },\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset will be written out to a file called `synthetic_data.jsonl` below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('synthetic_data.jsonl', 'w') as f:\n",
    "    for item in question_response_pair_list:\n",
    "        f.write(json.dumps(item))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Nemotron-4 340B Reward to Generate a Preference Dataset\n",
    "\n",
    "Equipped with a dataset that has questions that have response pairs, a preference dataset that is compatible with DPO training, SteerLM reward model training, and RLHF reward model training can be generated straightforwardly thanks to [Nemotron-4 340B Reward](https://build.nvidia.com/nvidia/nemotron-4-340b-reward) available through [build.nvidia.com](https://build.nvidia.com/)!\n",
    "\n",
    "First, an example of how to use the endpoint.\n",
    "\n",
    "1. You must both provide a user message, and an assistant message!\n",
    "2. It will return a chat-style message with the scores, as well as the scores in the `logprogs` parameter.\n",
    "\n",
    "The response package will include scores related to five attributes:\n",
    "\n",
    "1. Helpfulness: Overall helpfulness of the response to the prompt.\n",
    "2. Correctness: Inclusion of all pertinent facts without errors.\n",
    "3. Coherence: Consistency and clarity of expression.\n",
    "4. Complexity: Intellectual depth required to write response (i.e. whether the response can be written by anyone with basic language competency or requires deep domain expertise).\n",
    "5. Verbosity: Amount of detail included in the response, relative to what is asked for in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : \"Hello!\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello! How can I help you today?\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await client.chat.completions.create(\n",
    "        model=\"nvidia/nemotron-4-340b-reward\",\n",
    "        messages=messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='50010ecc-e198-4a14-8a7f-6b2fee9e2c45', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=4.09375, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=4.03125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=4.25, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.5703125, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.109375, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:4.09375,correctness:4.03125,coherence:4.25,complexity:0.5703125,verbosity:1.109375', refusal=None, role='assistant', function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=54, total_tokens=55, completion_tokens_details=None))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `logprobs` can be handled in a similar fashion to message content, as demonstrated below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=4.09375, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=4.03125, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=4.25, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.5703125, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.109375, top_logprobs=[])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].logprobs.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to define a simple helper function that can extract the scores to be used in the construction of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_from_response(openai_response_template):\n",
    "    logprobs = openai_response_template.choices[0].logprobs.content\n",
    "    score_dict = {}\n",
    "    for score in logprobs:\n",
    "        score_dict[score.token] = score.logprob\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'helpfulness': 4.09375,\n",
       " 'correctness': 4.03125,\n",
       " 'coherence': 4.25,\n",
       " 'complexity': 0.5703125,\n",
       " 'verbosity': 1.109375}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores_from_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the synthetic data generation above, using `asyncio` will help provide scores in a time-efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_response_and_scores(client, model, question, response_content):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response_content\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    scores = get_scores_from_response(response)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the list is important to avoid overwriting or modifying the original data - though it can be reloaded from `JSONL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_score_list = question_response_pair_list.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are calculated efficiently using `asyncio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_question_response_pairs(client, model, question_response_score_list):\n",
    "    tasks = []\n",
    "    for question_response_pair in question_response_score_list:\n",
    "        question = question_response_pair[\"question\"]\n",
    "        \n",
    "        task_a = get_response_and_scores(client, model, question, question_response_pair[\"responses\"][\"response_a\"][\"response\"])\n",
    "        task_b = get_response_and_scores(client, model, question, question_response_pair[\"responses\"][\"response_b\"][\"response\"])\n",
    "        \n",
    "        tasks.append((task_a, question_response_pair, \"response_a\"))\n",
    "        tasks.append((task_b, question_response_pair, \"response_b\"))\n",
    "    \n",
    "    results = await asyncio.gather(*[task[0] for task in tasks])\n",
    "    \n",
    "    for i, (result, task_info) in enumerate(zip(results, tasks)):\n",
    "        _, question_response_pair, response_key = task_info\n",
    "        question_response_pair[\"responses\"][response_key].update(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing left to do but fire it off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "await process_question_response_pairs(client, \"nvidia/nemotron-4-340b-reward\", question_response_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality can be relatively preserved by only keeping rows that have at least a `3.0` in the overall metric - in this case helpfulness. This will help ensure that the data remains high quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FInally, the dataset can be exported in `.JSONL` format for use in [NeMo Aligner](https://github.com/NVIDIA/NeMo-Aligner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'synthetic_data_with_scores_filtered-{threshold}.jsonl', 'w') as f:\n",
    "    for item in question_response_score_list:\n",
    "        question = item[\"question\"]\n",
    "        response_a = item[\"responses\"][\"response_a\"]\n",
    "        response_b = item[\"responses\"][\"response_b\"]\n",
    "        response_a[\"question\"] = question\n",
    "        response_b[\"question\"] = question\n",
    "        if response_a[\"helpfulness\"] < threshold and response_b[\"helpfulness\"] < threshold:\n",
    "            continue\n",
    "        f.write(json.dumps(response_a))\n",
    "        f.write('\\n')\n",
    "        f.write(json.dumps(response_b))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
